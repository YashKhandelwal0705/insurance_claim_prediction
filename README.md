# ðŸ›¡ï¸ Insurance Claim Severity Predictor

A comprehensive machine learning solution for predicting insurance claim severity based on policy and vehicle details. This project uses advanced feature engineering, multiple ML algorithms, and explainable AI to provide actionable insights for insurance claim assessment.

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Status](https://img.shields.io/badge/status-active-success.svg)

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [Technical Details](#technical-details)
- [Web Application](#web-application)
- [Contributing](#contributing)
- [License](#license)

## ðŸŽ¯ Overview

This project predicts the potential severity (cost) of insurance claims using machine learning. It analyzes factors such as:
- Driver demographics (age, claim history)
- Vehicle information (type, make, age)
- Accident details (type, region)

The solution includes:
- **Data preprocessing & feature engineering** with 32+ engineered features
- **Multiple ML models** (Linear Regression, Random Forest, XGBoost)
- **Model explainability** using SHAP (SHapley Additive exPlanations)
- **Interactive web application** built with Streamlit
- **Comprehensive model evaluation** and business insights

## âœ¨ Features

### Machine Learning Pipeline
- âœ… Automated feature engineering with polynomial and interaction features
- âœ… Multiple model training with hyperparameter tuning
- âœ… Cross-validation and rigorous model evaluation
- âœ… Log-transformed target variable for better predictions

### Model Explainability
- ðŸ“Š SHAP waterfall plots for individual predictions
- ðŸ” Feature importance analysis
- ðŸ’¡ Business-friendly risk factor insights

### Web Application
- ðŸ–¥ï¸ User-friendly Streamlit interface
- ðŸ“ˆ Real-time predictions with confidence metrics
- ðŸ§  Visual explanations of predictions
- ðŸŽ¯ Actionable business insights

## ðŸ“ Project Structure

```
insurance_claim_prediction/
â”‚
â”œâ”€â”€ app.py                          # Streamlit web application
â”œâ”€â”€ evaluate_model.py               # Model evaluation script
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ setup.py                        # Package setup configuration
â”œâ”€â”€ README.md                       # Project documentation
â”‚
â”œâ”€â”€ data/                           # Data directory
â”‚   â”œâ”€â”€ insurance_claims.csv        # Raw dataset
â”‚   â”œâ”€â”€ train.csv                   # Training data
â”‚   â”œâ”€â”€ test.csv                    # Test data
â”‚   â”œâ”€â”€ train_engineered.csv        # Engineered training features
â”‚   â””â”€â”€ test_engineered.csv         # Engineered test features
â”‚
â”œâ”€â”€ models/                         # Saved model artifacts
â”‚   â”œâ”€â”€ best_model.pkl              # Best performing model
â”‚   â”œâ”€â”€ tree_preprocessor.pkl       # Preprocessing pipeline
â”‚   â”œâ”€â”€ linear_preprocessor.pkl     # Linear model preprocessor
â”‚   â”œâ”€â”€ shap_explainer.pkl          # SHAP explainer object
â”‚   â””â”€â”€ generate_shap_explainer.py  # SHAP explainer generation
â”‚
â”œâ”€â”€ notebooks/                      # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # Initial data exploration
â”‚   â”œâ”€â”€ 02_eda_analysis.ipynb       # Exploratory data analysis
â”‚   â””â”€â”€ 03_model_evaluation.ipynb   # Model evaluation & comparison
â”‚
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ data/                       # Data processing modules
â”‚   â”‚   â”œâ”€â”€ preprocessing.py        # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ feature_engineering.py  # Feature engineering pipeline
â”‚   â”‚   â””â”€â”€ generate_synthetic_data.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                     # Model training & evaluation
â”‚   â”‚   â”œâ”€â”€ model_training.py       # Model training pipeline
â”‚   â”‚   â”œâ”€â”€ model_evaluation.py     # Model evaluation utilities
â”‚   â”‚   â”œâ”€â”€ model_explainability.py # SHAP & interpretability
â”‚   â”‚   â””â”€â”€ hyperparameter_tuning.py
â”‚   â”‚
â”‚   â”œâ”€â”€ business/                   # Business logic
â”‚   â”‚   â””â”€â”€ business_translation.py # Convert predictions to insights
â”‚   â”‚
â”‚   â””â”€â”€ utils/                      # Utility functions
â”‚       â””â”€â”€ app_utils.py            # Helper functions for app
â”‚
â””â”€â”€ reports/                        # Generated reports
    â”œâ”€â”€ feature_importance.csv      # Feature importance scores
    â”œâ”€â”€ model_evaluation_results.csv
    â”œâ”€â”€ sample_predictions.csv
    â””â”€â”€ figures/                    # Visualization outputs
```

## ðŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Step 1: Clone the Repository
```bash
git clone https://github.com/YashKhandelwal0705/insurance_claim_prediction.git
cd insurance_claim_prediction
```

### Step 2: Create Virtual Environment (Recommended)
```bash
# Windows
python -m venv venv
.\venv\Scripts\activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

Or install as a package:
```bash
pip install -e .
```

## ðŸ“– Usage

### 1. Data Preparation & Feature Engineering
```bash
python src/data/generate_synthetic_data.py  # Generate synthetic data (if needed)
python src/data/feature_engineering.py      # Engineer features
```

### 2. Model Training
```bash
python src/models/model_training.py         # Train all models
python src/models/hyperparameter_tuning.py  # Fine-tune hyperparameters
```

### 3. Model Evaluation
```bash
python evaluate_model.py                    # Evaluate model performance
python src/models/model_explainability.py   # Generate SHAP explanations
```

### 4. Generate SHAP Explainer
```bash
python models/generate_shap_explainer.py    # Create SHAP explainer for app
```

### 5. Launch Web Application
```bash
streamlit run app.py
```

The application will open in your default browser at `http://localhost:8501`

## ðŸ“Š Model Performance

### Best Model: XGBoost Regressor

**Test Set Performance:**
- **RÂ² Score:** 0.9356 (93.56%)
- **MAE:** $963.07
- **RMSE:** $1,277.11
- **MAPE:** 17.80%

**Training Set Performance:**
- **RÂ² Score:** 0.9726 (97.26%)
- **MAE:** $715.66
- **RMSE:** $919.35
- **MAPE:** 12.51%

**Prediction Statistics:**
- **Actual Mean Claim (Test):** $7,587.34
- **Predicted Mean Claim (Test):** $7,454.09

### Model Comparison

| Model              | RÂ² Score | MAE ($) | RMSE ($) | Training Time |
|-------------------|----------|---------|----------|---------------|
| XGBoost           | 0.9356   | 963.07  | 1,277.11 | ~5 min        |
| Random Forest     | 0.9234   | 1,100+  | 1,500+   | ~3 min        |
| Linear Regression | 0.8567   | 1,500+  | 2,000+   | ~1 min        |

## ðŸ”§ Technical Details

### Feature Engineering
The project implements comprehensive feature engineering:

1. **Binning Features:**
   - Driver age groups: Young (18-25), Mid-age (25-40), Senior (40-60), Elderly (60+)
   - Vehicle age groups: New (0-5), Mid-age (5-10), Old (10-15), Very old (15+)

2. **Polynomial Features:**
   - Second-degree polynomials for numerical features
   - Interaction terms between key variables

3. **Interaction Features:**
   - Age Ã— Vehicle type
   - Vehicle age Ã— Make
   - Driver age Ã— Vehicle make

4. **Total Features:** 32 engineered features

### Preprocessing Pipeline
- **Categorical encoding:** One-Hot Encoding
- **Numerical scaling:** StandardScaler (for linear models)
- **Target transformation:** Log transformation (log1p)

### Model Architecture
```python
Pipeline([
    ('preprocessor', ColumnTransformer([
        ('cat', OneHotEncoder(), categorical_cols),
        ('num', StandardScaler(), numerical_cols)
    ])),
    ('model', XGBRegressor(
        n_estimators=300,
        max_depth=7,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8
    ))
])
```

## ðŸ–¥ï¸ Web Application

The Streamlit application provides:

### Features:
1. **Interactive Input Form:**
   - Driver age slider (18-80)
   - Past claims counter
   - Vehicle details (type, make, age)
   - Accident type and region selectors

2. **Prediction Dashboard:**
   - Estimated claim amount with currency formatting
   - Key risk factors with icons
   - Business-friendly insights

3. **Explainability Tab:**
   - SHAP waterfall plot
   - Feature contribution analysis
   - Visual explanation of prediction drivers

### Running the App:
```bash
streamlit run app.py
```

Navigate to `http://localhost:8501` to access the interface.

## ðŸ§ª Testing

Run model evaluation:
```bash
python evaluate_model.py
```

Expected output:
```
MODEL PERFORMANCE EVALUATION
============================================================

ðŸ“Š TEST SET PERFORMANCE:
------------------------------------------------------------
  MAE (Mean Absolute Error):        $    963.07
  RMSE (Root Mean Squared Error):   $  1,277.11
  RÂ² Score:                              0.9356 (93.56%)
  MAPE (Mean Absolute % Error):           17.80%

âœ… INTERPRETATION:
------------------------------------------------------------
  ðŸŒŸ EXCELLENT: Model explains >90% of variance!
  âœ… GOOD: Average prediction error <20%
```

## ðŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ðŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ‘¤ Author

**Yash Khandelwal**
- GitHub: [@YashKhandelwal0705](https://github.com/YashKhandelwal0705)

## ðŸ™ Acknowledgments

- XGBoost library for high-performance gradient boosting
- SHAP library for model interpretability
- Streamlit for the web application framework
- scikit-learn for ML utilities and preprocessing

## ðŸ“ž Contact

For questions or feedback, please open an issue on GitHub or contact the author.

---

â­ If you find this project helpful, please consider giving it a star!
